{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MW2TvSzTeblH"
      },
      "outputs": [],
      "source": [
        "# ==== CONFIG (fill these) ====\n",
        "GOOGLE_API_KEY = \"AIzaSyCyZ9Ohi-GjjrWdSjLqjACA29OGxW7PwJ8\"\n",
        "GOOGLE_CX      = \"c5975b4dcae7f47a6\"\n",
        "USDA_API_KEY   = \"lJb2tUJxc7C5s8SZxoc3q2o6sRvlGJwDxFB8Qzbf\"\n",
        "PREFERRED_SITES = [\"walmart.com\", \"target.com\"]\n",
        "\n",
        "# ==== IMPORTS ====\n",
        "import re, json, time, requests\n",
        "from urllib.parse import quote_plus\n",
        "from bs4 import BeautifulSoup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psUMRamgex86",
        "outputId": "7fe3310f-1764-4b5d-d0d3-591003a27c22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"MBZUAI/LaMini-Flan-T5-783M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "GQdfTTU_e4Ye"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_meal_plan(ingredients, max_length=2048):\n",
        "    prompt = (\n",
        "        \"You are a helpful vegan chef assistant. \"\n",
        "        \"Write a beginner-friendly recipe using ONLY these ingredients when possible: \"\n",
        "        f\"{', '.join(ingredients)}. \"\n",
        "        \"Give the meal a title and an 'Ingredients:' section with one ingredient per line. \"\n",
        "        \"Do NOT include any instructions.\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Normalize and remove any accidental instructions the model might add\n",
        "    normalized = normalize_recipe_text(response)\n",
        "    normalized = strip_instructions(normalized)\n",
        "    return normalized\n"
      ],
      "metadata": {
        "id": "nSAqug-ie7Je"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BULLET_PAT = re.compile(r\"^\\s*([\\-–•]|\\d+\\.)\\s*\")  # -, –, •, or \"1.\"\n",
        "\n",
        "def extract_ingredient_lines(text: str):\n",
        "    \"\"\"\n",
        "    Robustly pull the bullet lines under the Ingredients section.\n",
        "    - Skips leading blanks after the header\n",
        "    - Stops at the next section header or when bullet list ends\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "\n",
        "    # find \"Ingredients\" header (allow variations like \"Ingredients -\" or \"Ingredients:\")\n",
        "    start_idx = None\n",
        "    for i, line in enumerate(lines):\n",
        "        if re.match(r\"^\\s*ingredients?\\s*[:\\-]?\\s*$\", line.strip(), re.I):\n",
        "            start_idx = i + 1\n",
        "            break\n",
        "    if start_idx is None:\n",
        "        return []\n",
        "\n",
        "    # skip blank lines after header\n",
        "    i = start_idx\n",
        "    while i < len(lines) and not lines[i].strip():\n",
        "        i += 1\n",
        "\n",
        "    collected = []\n",
        "    started = False\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "\n",
        "        # stop at a new section header\n",
        "        if re.match(r\"^\\s*(instructions|method|directions|steps?)\\s*[:\\-]?\\s*$\", line.strip(), re.I):\n",
        "            break\n",
        "\n",
        "        # bullet line?\n",
        "        if BULLET_PAT.search(line):\n",
        "            collected.append(line)\n",
        "            started = True\n",
        "        else:\n",
        "            # if we already started collecting bullets and hit a non-bullet (or empty) line, end\n",
        "            if started and (not line.strip() or not BULLET_PAT.search(line)):\n",
        "                break\n",
        "            # if we haven't started yet and it's still blank, just keep moving\n",
        "        i += 1\n",
        "\n",
        "    return collected\n",
        "\n",
        "UNITS = r\"cup|cups|tbsp|tablespoon|tablespoons|tsp|teaspoon|teaspoons|oz|ounce|ounces|lb|pound|pounds|g|kg|can|cans|clove|cloves|bag|bags|pinch\"\n",
        "PREP_WORDS = r\"chopped|minced|sliced|diced|fresh|drained|rinsed|to\\s+taste|optional|ground|grated|julienned|crushed|peeled|seeded|cooked|uncooked|firm|extra|frozen|of\"\n",
        "\n",
        "\n",
        "def normalize_name(s: str):\n",
        "    s = s.lower()\n",
        "    # remove quantities like \"1\", \"1/2\", \"2-3\", \"15 oz\", \"2 cups\"\n",
        "    s = re.sub(r\"\\b\\d+\\/\\d+\\b\", \" \", s)             # fractions\n",
        "    s = re.sub(r\"\\b\\d+\\b\", \" \", s)                  # integers\n",
        "    s = re.sub(rf\"\\b({UNITS})\\b\", \" \", s, flags=re.I)\n",
        "    s = re.sub(r\"[()]\", \" \", s)\n",
        "    # remove “, chopped” style descriptors\n",
        "    s = re.sub(rf\"\\b({PREP_WORDS})\\b\", \" \", s, flags=re.I)\n",
        "    # remove punctuation, extra words\n",
        "    s = re.sub(r\"[^a-z0-9 ]+\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "import re\n",
        "\n",
        "def normalize_recipe_text(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Make the LLM output parser-friendly:\n",
        "    - Put a newline before/after 'Ingredients:' and 'Instructions:'\n",
        "    - Put each '-' bullet on its own line\n",
        "    - Put each numbered step '1.' '2.' on its own line\n",
        "    \"\"\"\n",
        "    t = raw.replace(\"\\r\", \"\")\n",
        "\n",
        "    # Force headers onto their own lines\n",
        "    t = re.sub(r'\\s*Ingredients\\s*:?', '\\nIngredients:\\n', t, flags=re.I)\n",
        "    t = re.sub(r'\\s*Instructions\\s*:?', '\\nInstructions:\\n', t, flags=re.I)\n",
        "\n",
        "    # Ensure each bullet starts a new line\n",
        "    t = re.sub(r'\\s*-\\s+', '\\n- ', t)\n",
        "\n",
        "    # Ensure numbered steps start a new line (1., 2., 10., etc.)\n",
        "    t = re.sub(r'(?<!\\n)(\\b\\d+\\.)\\s*', r'\\n\\1 ', t)\n",
        "\n",
        "    # Collapse double/triple newlines\n",
        "    t = re.sub(r'\\n{3,}', '\\n\\n', t)\n",
        "\n",
        "    return t.strip()\n",
        "\n",
        "def strip_instructions(text: str) -> str:\n",
        "    # remove anything from 'Instructions' onward\n",
        "    return re.split(r'\\n\\s*Instructions\\s*:?', text, maxsplit=1, flags=re.I)[0].strip()\n",
        "\n",
        "def parse_recipe_ingredients(recipe_text: str):\n",
        "    def normalize_name(s: str):\n",
        "        s = s.lower()\n",
        "        s = re.sub(r\"\\b\\d+\\/\\d+\\b\", \" \", s)           # 1/2\n",
        "        s = re.sub(r\"\\b\\d+(?:\\.\\d+)?\\b\", \" \", s)      # 1, 1.5\n",
        "        s = re.sub(rf\"\\b({UNITS})\\b\", \" \", s, flags=re.I)\n",
        "        s = re.sub(r\"[()]\", \" \", s)\n",
        "        s = re.sub(rf\"\\b({PREP_WORDS})\\b\", \" \", s, flags=re.I)\n",
        "        s = re.sub(r\"[^a-z0-9 ]+\", \" \", s)\n",
        "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "        return s\n",
        "\n",
        "    def clean_ingredient_name(line: str):\n",
        "        line = BULLET_PAT.sub(\"\", line).strip()\n",
        "        line = line.replace(\"–\", \"-\")\n",
        "        line = line.split(\" - \")[0]\n",
        "        line = line.replace(\",\", \" \")\n",
        "        return normalize_name(line)\n",
        "\n",
        "    raw_lines = extract_ingredient_lines(recipe_text)\n",
        "    names = [clean_ingredient_name(ln) for ln in raw_lines]\n",
        "    names = [n for n in names if n]  # drop empties\n",
        "\n",
        "    # dedupe, preserve order\n",
        "    seen, uniq = set(), []\n",
        "    for n in names:\n",
        "        if n not in seen:\n",
        "            uniq.append(n); seen.add(n)\n",
        "    return uniq\n"
      ],
      "metadata": {
        "id": "FKlG-pLwfH7v"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(a: str, b: str):\n",
        "    A = set(a.split())\n",
        "    B = set(b.split())\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def split_have_missing(pantry_list, recipe_ings, threshold=0.5):\n",
        "    \"\"\"\n",
        "    pantry_list: list of strings user has (e.g., [\"rice\", \"beans\", \"tofu\"])\n",
        "    recipe_ings: normalized names from recipe\n",
        "    threshold: token overlap to consider a match\n",
        "    \"\"\"\n",
        "    pantry_norm = [normalize_name(x) for x in pantry_list]\n",
        "    have, missing = [], []\n",
        "    for ing in recipe_ings:\n",
        "        matched = any(jaccard(ing, p) >= threshold or ing in p or p in ing\n",
        "                      for p in pantry_norm)\n",
        "        (have if matched else missing).append(ing)\n",
        "    return have, missing\n"
      ],
      "metadata": {
        "id": "U7kI8ysqfKc6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cse_first_product_url(query, site):\n",
        "    q = f\"site:{site} {query}\"\n",
        "    url = ( \"https://www.googleapis.com/customsearch/v1\"\n",
        "            f\"?key={GOOGLE_API_KEY}&cx={GOOGLE_CX}&q={quote_plus(q)}\")\n",
        "    r = requests.get(url, timeout=12)\n",
        "    if r.status_code != 200:\n",
        "        return None, f\"cse_http_{r.status_code}\"\n",
        "    data = r.json()\n",
        "    items = data.get(\"items\") or []\n",
        "    if not items:\n",
        "        return None, \"cse_no_items\"\n",
        "    # prefer product-looking links\n",
        "    for it in items:\n",
        "        link = it.get(\"link\", \"\")\n",
        "        if any(p in link for p in [\"/ip/\",\"/p/\",\"/product/\",\"/gp/\"]):\n",
        "            return link, None\n",
        "    return items[0].get(\"link\"), None\n",
        "\n",
        "def best_store_url(item, sites=PREFERRED_SITES, delay=0.2):\n",
        "    for site in sites:\n",
        "        url, err = cse_first_product_url(item, site)\n",
        "        if url:\n",
        "            return {\"store\": site, \"url\": url, \"reason\": None}\n",
        "        last_err = err\n",
        "        time.sleep(delay)\n",
        "    return {\"store\": None, \"url\": None, \"reason\": last_err}\n"
      ],
      "metadata": {
        "id": "q_lDGKOtfLp0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_MACROS = {\n",
        "    \"Energy\": \"Calories\",\n",
        "    \"Protein\": \"Protein (g)\",\n",
        "    \"Total lipid (fat)\": \"Fat (g)\",\n",
        "    \"Carbohydrate, by difference\": \"Carbs (g)\",\n",
        "    \"Fiber, total dietary\": \"Fiber (g)\",\n",
        "    \"Sugars, total including NLEA\": \"Sugars (g)\",\n",
        "}\n",
        "\n",
        "def usda_macros(query):\n",
        "    url = \"https://api.nal.usda.gov/fdc/v1/foods/search\"\n",
        "    params = {\"query\": query, \"pageSize\": 1, \"api_key\": USDA_API_KEY}\n",
        "    try:\n",
        "        r = requests.get(url, params=params, timeout=12)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        foods = data.get(\"foods\", [])\n",
        "        if not foods:\n",
        "            return None, \"usda_no_match\"\n",
        "        f = foods[0]\n",
        "        out = {}\n",
        "        for n in f.get(\"foodNutrients\", []):\n",
        "            nm = n.get(\"nutrientName\")\n",
        "            if nm in MAIN_MACROS:\n",
        "                out[MAIN_MACROS[nm]] = n.get(\"value\")\n",
        "        # ensure stable keys\n",
        "        for k in MAIN_MACROS.values():\n",
        "            out.setdefault(k, None)\n",
        "        meta = {\"description\": f.get(\"description\",\"N/A\"),\n",
        "                \"brand\": f.get(\"brandOwner\",\"N/A\"),\n",
        "                \"fdcId\": f.get(\"fdcId\")}\n",
        "        return {\"macros\": out, \"meta\": meta}, None\n",
        "    except requests.RequestException as e:\n",
        "        return None, f\"usda_http_error:{e}\"\n"
      ],
      "metadata": {
        "id": "BtGU2HfefNv4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plan_and_enrich(pantry_list):\n",
        "    # 1) generate recipe\n",
        "    recipe_text = generate_meal_plan(pantry_list)\n",
        "\n",
        "    # 2) parse ingredients from recipe\n",
        "    recipe_ings = parse_recipe_ingredients(recipe_text)\n",
        "\n",
        "    # 3) compare to pantry\n",
        "    have, missing = split_have_missing(pantry_list, recipe_ings, threshold=0.5)\n",
        "\n",
        "    # 4) for each missing: store URL + USDA macros\n",
        "    enriched = []\n",
        "    for item in missing:\n",
        "        url_block = best_store_url(item)\n",
        "        usda_block, usda_err = usda_macros(item)\n",
        "        enriched.append({\n",
        "            \"item\": item,\n",
        "            \"store\": url_block[\"store\"],\n",
        "            \"url\": url_block[\"url\"],\n",
        "            \"url_reason\": url_block[\"reason\"],\n",
        "            \"macros\": (usda_block or {}).get(\"macros\") if usda_block else None,\n",
        "            \"usda_meta\": (usda_block or {}).get(\"meta\") if usda_block else None,\n",
        "            \"macros_reason\": None if usda_block else usda_err\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"recipe_text\": recipe_text,\n",
        "        \"parsed_ingredients\": recipe_ings,\n",
        "        \"have\": have,\n",
        "        \"missing\": missing,\n",
        "        \"shopping_info\": enriched\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ZBuEe141fRxk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pantry = [\"rice\", \"beans\", \"tofu\", \"potato\"]  # student’s on-hand list\n",
        "result = plan_and_enrich(pantry)\n",
        "\n",
        "# Show recipe as-is\n",
        "print(result[\"recipe_text\"])\n",
        "\n",
        "print(\"\\nParsed ingredients:\", result[\"parsed_ingredients\"])\n",
        "print(\"\\nYou already have:\", result[\"have\"])\n",
        "print(\"\\nYou need to buy:\")\n",
        "for row in result[\"shopping_info\"]:\n",
        "    print(f\" - {row['item']}\")\n",
        "    print(f\"   store: {row['store'] or 'n/a'}\")\n",
        "    print(f\"   url:   {row['url'] or row['url_reason']}\")\n",
        "    print(f\"   macros: {row['macros']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izqXVArPfS7z",
        "outputId": "3e2cab70-1c9e-45c2-e356-322932b395e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe: Tofu and Bean Stir Fry\n",
            "Ingredients:\n",
            "- 1 cup rice\n",
            "- 1 block firm tofu, cubed\n",
            "- 1 diced potato\n",
            "- 1 tablespoon vegetable oil\n",
            "- 1 tablespoon soy sauce\n",
            "- 1 tablespoon sesame oil\n",
            "- 1 teaspoon ginger, minced\n",
            "- 1 teaspoon garlic, minced\n",
            "- 1 tablespoon soy sauce\n",
            "- Salt and pepper to taste\n",
            "\n",
            "Parsed ingredients: ['rice', 'block tofu cubed', 'potato', 'vegetable oil', 'soy sauce', 'sesame oil', 'ginger', 'garlic', 'salt and pepper']\n",
            "\n",
            "You already have: ['rice', 'block tofu cubed', 'potato']\n",
            "\n",
            "You need to buy:\n",
            " - vegetable oil\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Great-Value-Vegetable-Oil-48-fl-oz/10451002\n",
            "   macros: {'Protein (g)': 0.0, 'Fat (g)': 100, 'Carbs (g)': 0.0, 'Calories': 857, 'Fiber (g)': None, 'Sugars (g)': None}\n",
            " - soy sauce\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Kikkoman-Soy-Sauce-15-0-FL-OZ/10452918\n",
            "   macros: {'Protein (g)': 8.14, 'Fat (g)': 0.57, 'Carbs (g)': 4.93, 'Calories': 53, 'Fiber (g)': 0.8, 'Sugars (g)': None}\n",
            " - sesame oil\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Imperial-Dragon-100-Pure-Sesame-Seed-Oil-5-fl-oz/10451695\n",
            "   macros: {'Protein (g)': 0, 'Fat (g)': 100, 'Carbs (g)': 0, 'Calories': 884, 'Fiber (g)': 0, 'Sugars (g)': None}\n",
            " - ginger\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Fresh-Ginger-Root-Each/44391005\n",
            "   macros: {'Protein (g)': 0.0, 'Fat (g)': 0.0, 'Carbs (g)': 0.0, 'Calories': 0.0, 'Fiber (g)': None, 'Sugars (g)': None}\n",
            " - garlic\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Knorr-Cube-Bouillon-Garlic-20-ct/10291739\n",
            "   macros: {'Protein (g)': 0.0, 'Fat (g)': 0.0, 'Carbs (g)': 33.3, 'Calories': 167, 'Fiber (g)': None, 'Sugars (g)': None}\n",
            " - salt and pepper\n",
            "   store: walmart.com\n",
            "   url:   https://www.walmart.com/ip/Morton-Salt-Iodized-Salt-McCormick-Black-Pepper-5-25-oz-Shaker-Set/25120110\n",
            "   macros: {'Protein (g)': 0.0, 'Fat (g)': 0.0, 'Carbs (g)': 0.0, 'Calories': 0.0, 'Fiber (g)': 0.0, 'Sugars (g)': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rndu0edCfZvk"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}